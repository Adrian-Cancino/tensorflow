{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing MLPs with Keras\n",
        "\n",
        "### What is **MLPs**?\n",
        "\n",
        "Multilayer Perceptron (MLP) is a type of artificial neural network. This consists of one or more hidden layers of nodes, which are fully connected to the input and output layers. Each node in the hidden layer applies a linear transformation to the input and passes the result through a non-linear activation function.\n",
        "\n",
        "**Perceptron** refers to a single-layer neural network and **Mulyilayer Perceptrion** refers to a neural network with multiple layers.\n",
        "\n",
        "**MLPs** are supervised learning models, which means that they are trained using labeled data.\n",
        "\n",
        "## Building an Image Classifier Using the Sequential API\n",
        "\n",
        "In this case we are going to use a replacement of **MNIST** dataset, the **Fashion MNIST**. It has the exact same format as MNIST (70,000 grayscale images of 28 * 28 pixels each, with 10 classes), but the images represent fashion items rather than handwritten digits.\n",
        "\n",
        "### Load the dataset\n",
        "\n",
        "Keras provide functions to fetch and load common datasets. **Fashion MNIST** it's already shuffled and split into a training set (60,000 images) and a test set (10,000 images).\n",
        "\n",
        "We'll hold out the last 5,000 images from training set for validation."
      ],
      "metadata": {
        "id": "AD9hatedzx1q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13k6JMINxoVW",
        "outputId": "72017e96-af9d-4240-9340-57f4c4adf25f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n",
        "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist\n",
        "X_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\n",
        "X_valid, y_valid = X_train_full[-5000:], y_train_full[-5000:]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When loading **Fasion MNIST** using Keras every image is represented as a 28 * 28 array. Moreover, the pixel intensities are represented as integers."
      ],
      "metadata": {
        "id": "nayfMytQ3EVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmTp7mQt24eV",
        "outputId": "876a26f2-2681-4bde-a82f-02aa03f5a520"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(55000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For simplicity, we’ll scale the pixel intensities down to the 0–1 range by dividing them by 255.0 (this also converts them to floats):"
      ],
      "metadata": {
        "id": "WwFBJUQo4YJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_valid, X_test = X_train / 255., X_valid / 255., X_test / 255."
      ],
      "metadata": {
        "id": "WknWU-DK3BPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For **Fashion MNIST** we need the list of class names to know what we are dealing with."
      ],
      "metadata": {
        "id": "_8_H6tgP4dIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
        "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n"
      ],
      "metadata": {
        "id": "5ILbVsYW4aqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see what represent the first image of the training set."
      ],
      "metadata": {
        "id": "CLBHr4iT5dwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_names[y_train[0]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "CMpoLF2C5Zaj",
        "outputId": "89eb53d0-af31-4612-88b0-7fdd9a770b6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ankle boot'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creaing the model using the sequential API"
      ],
      "metadata": {
        "id": "WLuqzdxF5nfr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Input(shape=[28, 28]))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(300, activation=\"relu\"))\n",
        "model.add(tf.keras.layers.Dense(100, activation=\"relu\"))\n",
        "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "ScUB64yE5lrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `tf.random.set_seed(42)`: sets a random seed for Tensorflow to ensure that the results are reproducible.\n",
        "- `model = tf.keras.Sequential()`: The Sequential model in Keras API is a linear stack of layers that allow you to build a neural network model layer by layer. As we can see in the code, we add layers with different values.\n",
        "- `model.add(tf.keras.layers.Input(shape=[28, 28]))`: This layer is used to define the input shape of the neural network. In this case we create an input layer for the model with a shape of *(28,28)*, which corresponds to the dimensions of the input omages in the Fashion MNIST dataset. With this info, Tensorflow will automatically infer the shapes of the intermediate layers in the network. This is because the input layer serves as the starting point for the forward propagation of the input data through the network.\n",
        "- `model.add(tf.keras.layers.Flatten())`: This reshapes the input data into a 1-dimensional array.\n",
        "- `model.add(tf.keras.layers.Dense(300, activation=\"relu\"))`: Adds a dense layer to the model with 300 neurons and a ReLU activation function. The dense layer is fully connected, which means that each neuron is connected to every neuron in the previously layer.\n",
        "> ReLU stans for Rectified Linear Unit and it is a type of activation function used in neural networks. The ReLU activation function is defined as f(x) = max(0, x), which means that if the input x is greater than zero, the output will be equal to x, and if x is less than or equal to zero, the output will be zero.\n",
        "- `model.add(tf.keras.layers.Dense(100, activation=\"relu\"))`: This layer takes the output of the first dense layer, which has 300 neurons, and applies a second set of weights to produce a new set of 100 activations. The purpose of adding a second layer is to allow the neural network to learn more complex relationships between the input and output.\n",
        "- `model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))`: This line adds the output layer to the model with 10 neurons (one for each class in the Fashion MNIST dataset). *softmax* produces a probability distribution over the 10 classes.\n",
        "\n",
        "We can do this in instead:\n",
        "\n",
        "```\n",
        "model = tf.keras.Sequential([\n",
        "\n",
        "  tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
        "\n",
        "  tf.keras.layers.Dense(300, activation=\"relu\"),\n",
        "\n",
        "  tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "\n",
        "  tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "\n",
        "])\n",
        "```\n",
        "\n",
        "When we get the model we can use the `summary()` method that displays all the model's layers, including each layer's name, its output shape, and its number of parameters."
      ],
      "metadata": {
        "id": "DrVYEbZM6PX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_NTCss66Lxr",
        "outputId": "6b52290d-92e8-4f1e-ed67-829c685a805a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 300)               235500    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 100)               30100     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 266,610\n",
            "Trainable params: 266,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `Dense` layer often have a lot of parameters. For example, the first hidden layer has 784 * 300 connections weights, plus 300 bias term, which adds up to 235,500 parameters. This gives the model quite a lot of flexibility to fit the training data, but it also means that the model runs the risk of overfitting, especially when you do not have a lot of training data.\n",
        "\n",
        "We can use the `layers` attributes to get the model's list of layers, or use the `get_layer()` method to access a layer by name."
      ],
      "metadata": {
        "id": "tU5mJ9SI2Pun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.layers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svQDNlbW2L5g",
        "outputId": "3fca613e-a872-4f2a-c47e-9ae72dc323d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.layers.reshaping.flatten.Flatten at 0x7f5de9a3e190>,\n",
              " <keras.layers.core.dense.Dense at 0x7f5d4df59f10>,\n",
              " <keras.layers.core.dense.Dense at 0x7f5d4c6c9d90>,\n",
              " <keras.layers.core.dense.Dense at 0x7f5d4c6c96a0>]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hidden = model.layers[1]\n",
        "hidden.name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "umpMofqI3SFM",
        "outputId": "d35e58e7-c690-45cf-facf-4b158ae59baf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'dense'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_layer('dense') is hidden"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-j1H7Hau3XT5",
        "outputId": "f2dc041c-699b-468a-aa3b-08c2074bd8ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compiling the model\n",
        "\n",
        "The method `compile()` method is used to specify the loss function and the optimizer to use."
      ],
      "metadata": {
        "id": "hNLlcHss3itw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=\"sgd\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "TvczcWcM3c0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `compile()` method is used to configure the model for training by specyfing the loss function, optimizer, and evaluating metrics.\n",
        "\n",
        "In the code we have the following parameters:\n",
        "\n",
        "- `loss`: This parameter specifies the loss function that the model will use to evaluate how well it is learning during training. The `\"sparse_categorical_crossentropy\"` loss function is commonly used for multi-class classification problems where the target variable is represented as integers.\n",
        "- `optimizer`: The `sgd` optimizer stands for Stochastic Gradient Descent and is a common choice for neural network training.\n",
        "- `metrics`: This parameter specifies the evaluation metric that will be used to monitor the performance of the model during training and testing. In this case, we are using the `\"accuracy\"` metric to tack how ofthen the model correctly predicts the class of the input data.\n",
        "\n",
        "Now we can then move on to training the model using the `fit()` method.\n",
        "\n",
        "### Training and evaluating the model"
      ],
      "metadata": {
        "id": "MgVhFtUB4BMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=30,\n",
        "                    validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5G4l6qS73vwn",
        "outputId": "61abb3e3-bffb-43bd-d848-4784e16e48ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.7084 - accuracy: 0.7698 - val_loss: 0.4945 - val_accuracy: 0.8310\n",
            "Epoch 2/30\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4841 - accuracy: 0.8325 - val_loss: 0.4583 - val_accuracy: 0.8346\n",
            "Epoch 3/30\n",
            "1719/1719 [==============================] - 8s 4ms/step - loss: 0.4392 - accuracy: 0.8457 - val_loss: 0.4238 - val_accuracy: 0.8506\n",
            "Epoch 4/30\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4138 - accuracy: 0.8550 - val_loss: 0.3941 - val_accuracy: 0.8590\n",
            "Epoch 5/30\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3934 - accuracy: 0.8619 - val_loss: 0.3887 - val_accuracy: 0.8614\n",
            "Epoch 6/30\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3773 - accuracy: 0.8671 - val_loss: 0.3953 - val_accuracy: 0.8596\n",
            "Epoch 7/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3650 - accuracy: 0.8705 - val_loss: 0.3719 - val_accuracy: 0.8690\n",
            "Epoch 8/30\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3530 - accuracy: 0.8746 - val_loss: 0.3694 - val_accuracy: 0.8636\n",
            "Epoch 9/30\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3423 - accuracy: 0.8789 - val_loss: 0.3499 - val_accuracy: 0.8754\n",
            "Epoch 10/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3319 - accuracy: 0.8822 - val_loss: 0.3473 - val_accuracy: 0.8746\n",
            "Epoch 11/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3235 - accuracy: 0.8848 - val_loss: 0.3661 - val_accuracy: 0.8688\n",
            "Epoch 12/30\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3159 - accuracy: 0.8864 - val_loss: 0.3462 - val_accuracy: 0.8766\n",
            "Epoch 13/30\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3086 - accuracy: 0.8909 - val_loss: 0.3271 - val_accuracy: 0.8810\n",
            "Epoch 14/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3016 - accuracy: 0.8918 - val_loss: 0.3355 - val_accuracy: 0.8768\n",
            "Epoch 15/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2959 - accuracy: 0.8938 - val_loss: 0.3301 - val_accuracy: 0.8812\n",
            "Epoch 16/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2885 - accuracy: 0.8966 - val_loss: 0.3246 - val_accuracy: 0.8774\n",
            "Epoch 17/30\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2836 - accuracy: 0.8979 - val_loss: 0.3322 - val_accuracy: 0.8760\n",
            "Epoch 18/30\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2778 - accuracy: 0.8996 - val_loss: 0.3218 - val_accuracy: 0.8786\n",
            "Epoch 19/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2728 - accuracy: 0.9014 - val_loss: 0.3517 - val_accuracy: 0.8656\n",
            "Epoch 20/30\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2680 - accuracy: 0.9043 - val_loss: 0.3161 - val_accuracy: 0.8812\n",
            "Epoch 21/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2632 - accuracy: 0.9046 - val_loss: 0.3139 - val_accuracy: 0.8852\n",
            "Epoch 22/30\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2581 - accuracy: 0.9066 - val_loss: 0.3110 - val_accuracy: 0.8822\n",
            "Epoch 23/30\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2541 - accuracy: 0.9088 - val_loss: 0.3452 - val_accuracy: 0.8716\n",
            "Epoch 24/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2488 - accuracy: 0.9107 - val_loss: 0.3201 - val_accuracy: 0.8830\n",
            "Epoch 25/30\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2448 - accuracy: 0.9121 - val_loss: 0.3106 - val_accuracy: 0.8824\n",
            "Epoch 26/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2411 - accuracy: 0.9136 - val_loss: 0.3124 - val_accuracy: 0.8894\n",
            "Epoch 27/30\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2361 - accuracy: 0.9144 - val_loss: 0.3149 - val_accuracy: 0.8846\n",
            "Epoch 28/30\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2331 - accuracy: 0.9167 - val_loss: 0.3060 - val_accuracy: 0.8892\n",
            "Epoch 29/30\n",
            "1719/1719 [==============================] - 8s 4ms/step - loss: 0.2288 - accuracy: 0.9175 - val_loss: 0.3134 - val_accuracy: 0.8824\n",
            "Epoch 30/30\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2253 - accuracy: 0.9191 - val_loss: 0.3041 - val_accuracy: 0.8886\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using the model to make predictions\n",
        "\n",
        "Now, we can use the model's `predict()` method to make predictions on new instances. To make predictions we're going to use the first three instances of the test set:"
      ],
      "metadata": {
        "id": "iVSp88qc8FPi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_new = X_test[:3]\n",
        "y_proba = model.predict(X_new)\n",
        "y_proba.round(2)"
      ],
      "metadata": {
        "id": "YdLNvWpf6Ed9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5c7f4b1-bca3-4f89-fb2b-32432ad0c1e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 255ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.01, 0.  , 0.98],\n",
              "       [0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
              "       [0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For each isntance the model estimates one proability per class, from class 0 to class 9. For example, for the first image it estimate that the probability of class 9 is 98%."
      ],
      "metadata": {
        "id": "kyyyG5vC8Yyf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "y_pred = model.predict(X_new)\n",
        "classes_y=np.argmax(y_pred,axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XA6sKWvH8WOP",
        "outputId": "c48a9b98-9886-4c65-ea38-7b815dddbf9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 65ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes_y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hx-0QFYN8xDO",
        "outputId": "74fbe200-a7cb-435c-cd27-01e632706e98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9, 2, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(class_names)[classes_y]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UolfS_X89Fwd",
        "outputId": "6031511f-32f1-430d-8422-7acb0224fe95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IF7yRPUl9zJ8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}